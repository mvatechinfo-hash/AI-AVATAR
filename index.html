<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI-AVATAR</title>

    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    
    <style>
        /* Import the Inter font for a clean look */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');
        
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            background: #111827;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        canvas {
            display: block;
            touch-action: none;
        }
        /* Styling for the main UI container */
        .chat-ui-container {
            position: absolute;
            bottom: 20px;
            right: 20px;
            top: 20px;
            padding: 1rem;
            width: 100%;
            max-width: 400px;
            z-index: 10;
            display: flex;
            flex-direction: column;
            background-color: rgba(31, 41, 55, 0.8);
            border-radius: 1rem;
            backdrop-filter: blur(5px);
            transition: opacity 0.5s ease-in-out;
        }
        #chat-history {
            flex-grow: 1;
            overflow-y: auto;
            padding: 1rem;
            border-radius: 0.75rem;
            background-color: #1f2937;
            margin-bottom: 1rem;
        }
        .chat-message {
            margin-bottom: 1rem;
            max-width: 80%;
            padding: 0.75rem 1rem;
            border-radius: 1.5rem;
            line-height: 1.5;
        }
        .user-message {
            background-color: #3b82f6;
            color: white;
            align-self: flex-end;
            margin-left: auto;
        }
        .bot-message {
            background-color: #4b5563;
            color: white;
            align-self: flex-start;
            margin-right: auto;
        }
        /* Pulse animation for the microphone button when listening */
        .listening-button {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 0 0 rgba(255, 255, 255, 0.7);
            }
            50% {
                transform: scale(1.1);
                box-shadow: 0 0 20px rgba(255, 255, 255, 1);
            }
        }
    </style>
    
    <!-- Load Tone.js for dynamic music generation -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.49/Tone.js"></script>
    
    <!-- Import maps for Three.js modules -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.165.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.165.0/examples/jsm/"
            }
        }
    </script>
</head>
<body class="bg-gray-900 text-white">

    <!-- The 3D canvas container -->
    <div id="canvas-container" class="fixed inset-0 z-0"></div>
    
    <!-- Loading screen for the 3D model -->
    <div id="loading-screen" class="fixed inset-0 z-50 flex flex-col items-center justify-center bg-gray-900 transition-opacity duration-500">
        <div class="animate-spin rounded-full h-16 w-16 border-t-2 border-b-2 border-blue-500"></div>
        <p class="mt-4 text-gray-300">Loading 3D model...</p>
    </div>

    <!-- The main chat UI container -->
    <div id="chat-ui" class="chat-ui-container opacity-0 hidden">
        <div id="chat-history" class="mb-4"></div>
        <div class="flex flex-col w-full space-y-2">
            <div class="flex space-x-2 w-full">
                <button id="mic-button" class="flex-grow bg-gray-600 text-white py-3 px-6 rounded-lg font-bold hover:bg-gray-700 transition-colors duration-200 shadow-md flex items-center justify-center">
                    <i class="fas fa-microphone"></i>
                </button>
                <button id="dance-button" class="flex-grow bg-purple-600 text-white py-3 px-6 rounded-lg font-bold hover:bg-purple-700 transition-colors duration-200 shadow-md flex items-center justify-center">
                    <i class="fas fa-music"></i>
                </button>
            </div>
            <div class="flex space-x-2 w-full">
                <input type="text" id="chat-input" placeholder="Type your message..." class="flex-grow p-3 rounded-lg bg-gray-700 text-white placeholder-gray-400 focus:outline-none focus:ring-2 focus:ring-blue-500">
                <button id="send-button" class="flex-grow bg-blue-600 text-white py-3 px-6 rounded-lg font-bold hover:bg-blue-700 transition-colors duration-200 shadow-md">
                    Send
                </button>
            </div>
        </div>
    </div>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';

        // --- Core Three.js and App Variables ---
        let scene, camera, renderer, avatar, mixer;
        const clock = new THREE.Clock();
        const raycaster = new THREE.Raycaster();
        const pointer = new THREE.Vector2();
        const groundPlane = new THREE.Plane(new THREE.Vector3(0, 1, 0), 0);

        let leftEye, rightEye, headBone, jawBone;
        const mouse = new THREE.Vector2();
        const lookAtTarget = new THREE.Vector3();

        const leftEyeBoneName = 'Eye_Left';
        const rightEyeBoneName = 'Eye_Right';
        const headBoneName = 'HeadTop_End_end';
        const jawBoneName = 'Jaw';
        const rotationLimit = 0.5;

        // API Key (Canvas will automatically handle this)
        const apiKey = ""; 
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;
        const ttsApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
        const ttsAudioContext = new (window.AudioContext || window.webkitAudioContext)();
        let ttsAudioSource = null;

        // --- UI Element References ---
        const loadingScreen = document.getElementById('loading-screen');
        const chatUiContainer = document.getElementById('chat-ui');
        const chatInput = document.getElementById('chat-input');
        const sendButton = document.getElementById('send-button');
        const micButton = document.getElementById('mic-button');
        const danceButton = document.getElementById('dance-button');
        const chatHistory = document.getElementById('chat-history');

        // --- Avatar State & Animation Management ---
        const animationNames = {
            idle: 'idle',
            idle2: 'idle2',
            wave: 'wave',
            talk: 'talk',
            listening: 'listen',
            thinking: 'think',
            shake: 'shake',
            walk: 'walk',
            dance: 'dance',
        };
        const greetings = [
            { initial: "Hello there!", followUp: "What can I do for you?" },
            { initial: "Hi!", followUp: "How can I help?" },
            { initial: "Hey!", followUp: "Nice to see you!" },
            { initial: "Greetings!", followUp: "Feel free to ask me anything." }
        ];
        let currentAction;
        const actions = {};

        let isGreeting = false;
        let isMoving = false;
        let isTurning = false;
        let isTalking = false;
        let isListening = false;
        
        let lastInteractionTime = Date.now();
        const IDLE_TIMEOUT_10 = 10 * 1000; // 10 seconds for idle2 -> idle
        const IDLE_TIMEOUT_30 = 30 * 1000; // 30 seconds for idle -> patrol
        let patrolTimeoutId = null;
        let idleTimeoutId = null;

        let targetQuaternion = new THREE.Quaternion();
        const turnDuration = 500;
        let turnStartTime = 0;

        let speechRecognition;
        let danceLoop;
        
        // --- Event Listeners and Initializers ---
        window.addEventListener('resize', onWindowResize);
        document.addEventListener('mousemove', onMouseMove);
        
        // Listen for clicks on the main avatar and chat UI to reset idle sequence
        document.body.addEventListener('mousedown', reactToInteraction);
        chatUiContainer.addEventListener('mousedown', (event) => {
            event.stopPropagation(); // Prevent clicks on chat UI from triggering canvas click
            reactToInteraction();
        });

        chatInput.addEventListener('keydown', (event) => {
            if (event.key === 'Enter') {
                onSendMessage();
            }
        });
        sendButton.addEventListener('click', onSendMessage);
        micButton.addEventListener('click', toggleSpeechRecognition);
        danceButton.addEventListener('click', onDanceButtonClick);
        
        // Initialize speech recognition early but do not start it
        initSpeechRecognition();

        // --- Main Three.js Initialization ---
        async function init() {
            const canvasContainer = document.getElementById('canvas-container');

            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x111827);

            camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 100);
            camera.position.set(0, 1.8, 3);

            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            canvasContainer.appendChild(renderer.domElement);
            renderer.domElement.addEventListener('mousedown', onCanvasClick, false);
            
            // Lighting
            const ambientLight = new THREE.AmbientLight(0xffffff, 1.2);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(1, 2, 3).normalize();
            scene.add(directionalLight);

            // Ground plane for raycasting and patrol
            const ground = new THREE.Mesh(
                new THREE.PlaneGeometry(100, 100),
                new THREE.MeshStandardMaterial({ color: 0x222222, visible: false })
            );
            ground.rotation.x = -Math.PI / 2;
            ground.position.y = -0.01;
            scene.add(ground);

            // Load the 3D model with loading progress
            const loader = new GLTFLoader();
            loader.load('./chatbot_avatar.glb', (gltf) => {
                avatar = gltf.scene;
                scene.add(avatar);
                console.log("Avatar loaded and added to scene.");

                // Set initial position and find bones for animation
                avatar.position.z = 0;
                avatar.position.y = 0;
                findBones(avatar);

                // Set up animation mixer and actions
                mixer = new THREE.AnimationMixer(avatar);
                gltf.animations.forEach(clip => {
                    const action = mixer.clipAction(clip);
                    actions[clip.name] = action;
                });
                
                // Event listener for animation finishes (e.g., wave or dance)
                mixer.addEventListener('finished', (event) => {
                    if (event.action._clip.name === animationNames.dance) {
                        stopDanceMusic();
                        playAction(animationNames.idle2, THREE.LoopRepeat);
                    } else if (event.action._clip.name === animationNames.wave) {
                         // After waving, immediately start the talk animation for the followup greeting
                        playAction(animationNames.talk, THREE.LoopRepeat);
                        const randomGreeting = greetings[Math.floor(Math.random() * greetings.length)];
                        speakText(randomGreeting.followUp, () => {
                            playAction(animationNames.idle2, THREE.LoopRepeat);
                            isGreeting = false;
                        });
                    }
                });

                // Hide loading screen and show chat UI after model is loaded
                setTimeout(() => {
                    loadingScreen.style.opacity = '0';
                    setTimeout(() => {
                        loadingScreen.classList.add('hidden');
                        chatUiContainer.classList.remove('hidden');
                        chatUiContainer.style.opacity = '1';
                        // Start the idle sequence and initial greeting
                        startGreetingSequence();
                        startIdleSequence();
                    }, 500);
                }, 500);
                
                animate(); // Start the animation loop
            }, (xhr) => {
                const percent = Math.round((xhr.loaded / xhr.total) * 100);
                document.querySelector('#loading-screen p').innerText = `Loading: ${percent}%`;
            }, (error) => {
                console.error('An error occurred while loading the GLTF model:', error);
                document.querySelector('#loading-screen p').innerText = 'Failed to load model. Please check the file path.';
            });
        }

        // --- Animation and State Logic ---
        function animate() {
            requestAnimationFrame(animate);

            const delta = clock.getDelta();
            const time = clock.getElapsedTime();

            // Lip-syncing: animate the jaw bone when the avatar is talking
            if (jawBone && isTalking) {
                const jawRotation = Math.sin(time * 15) * 0.05 + 0.02; // Increased frequency for more energy
                jawBone.rotation.x = -jawRotation;
            } else if (jawBone) {
                jawBone.rotation.x = 0;
            }
            
            // Avatar movement logic
            if (isMoving) {
                const distance = avatar.position.distanceTo(avatar.userData.targetPosition);

                if (distance > 0.05) {
                    if (isTurning) {
                        const elapsedTime = Date.now() - turnStartTime;
                        const turnProgress = Math.min(elapsedTime / turnDuration, 1);
                        avatar.quaternion.slerp(targetQuaternion, turnProgress);
                        if (turnProgress >= 1) {
                            isTurning = false;
                        }
                    } else {
                        const direction = new THREE.Vector3().subVectors(avatar.userData.targetPosition, avatar.position).normalize();
                        avatar.position.addScaledVector(direction, 0.008);
                    }
                } else {
                    avatar.position.copy(avatar.userData.targetPosition);
                    isMoving = false;
                    playAction(animationNames.idle2, THREE.LoopRepeat);
                    startIdleSequence(); // Restart idle sequence after reaching destination
                }
            }

            // Patrol logic (triggered from startIdleSequence)
            const now = Date.now();
            if (!isMoving && !isTalking && now - lastInteractionTime > IDLE_TIMEOUT_30) {
                startPatrol();
            } else if (!isMoving && !isTalking && now - lastInteractionTime > IDLE_TIMEOUT_10) {
                playAction(animationNames.idle, THREE.LoopRepeat);
            }
            
            // Update the animation mixer
            if (mixer) mixer.update(delta);
            renderer.render(scene, camera);
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function onMouseMove(event) {
            // Update mouse coordinates for look-at functionality
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;
            lastMouseMovementTime = Date.now();
        }

        // --- User Interaction and Core Logic Functions ---

        async function onCanvasClick(event) {
            reactToInteraction();
            faceCamera();
            const canvas = renderer.domElement;
            pointer.x = (event.clientX / canvas.clientWidth) * 2 - 1;
            pointer.y = -(event.clientY / canvas.clientHeight) * 2 + 1;

            raycaster.setFromCamera(pointer, camera);
            const intersects = raycaster.intersectObject(scene.children[1], true);

            if (intersects.length > 0) {
                const intersection = intersects[0];
                const point = intersection.point;

                if (intersection.object.name === 'Armature' || intersection.object.parent.name === 'Armature' || intersection.object.parent.parent.name === 'Armature') {
                    // Clicked on the avatar, trigger wave and greeting
                    stopPatrol();
                    playAction(animationNames.wave, THREE.LoopOnce);
                    const randomGreeting = greetings[Math.floor(Math.random() * greetings.length)];
                    speakText(randomGreeting.initial);
                    isGreeting = true;
                } else {
                    // Clicked on the ground, move avatar to that point
                    stopPatrol();
                    moveAvatarTo(point);
                }
            }
        }

        function reactToInteraction() {
            // This function is the central point for resetting the idle/patrol sequence
            lastInteractionTime = Date.now();
            if (isPatrolling) {
                stopPatrol();
            }
            if (!isMoving && !isTalking && !isListening) {
                playAction(animationNames.idle2, THREE.LoopRepeat);
            }
            startIdleSequence();
            faceCamera();
        }

        function faceCamera() {
            if (avatar) {
                const direction = new THREE.Vector3().subVectors(camera.position, avatar.position).setY(0).normalize();
                targetQuaternion.setFromUnitVectors(new THREE.Vector3(0, 0, 1), direction);
                isTurning = true;
                turnStartTime = Date.now();
            }
        }

        function moveAvatarTo(targetPosition) {
            if (!avatar) return;

            // Stop any patrol/idle sequence
            stopPatrol();
            playAction(animationNames.walk, THREE.LoopRepeat);
            
            // Set up movement state
            avatar.userData.targetPosition = new THREE.Vector3(targetPosition.x, avatar.position.y, targetPosition.z);
            isMoving = true;

            // Calculate the new rotation to face the target
            const direction = new THREE.Vector3().subVectors(avatar.userData.targetPosition, avatar.position);
            direction.y = 0; // Keep the avatar level
            direction.normalize();

            if (direction.lengthSq() > 0.001) { // Only rotate if there's a meaningful direction
                const newRotation = new THREE.Quaternion().setFromUnitVectors(new THREE.Vector3(0, 0, 1), direction);
                targetQuaternion.copy(newRotation);
                isTurning = true;
                turnStartTime = Date.now();
            }
        }

        // --- Chatbot and API Functions ---

        async function onSendMessage() {
            const message = chatInput.value.trim();
            if (message === '') return;
            
            // Handle special chat commands first
            if (message.toLowerCase() === 'dance') {
                reactToInteraction(); // This will stop patrol and start dance
                onDanceButtonClick();
                chatInput.value = '';
                return;
            }

            // Regular chat message handling
            appendMessage(message, 'user-message');
            chatInput.value = '';
            
            reactToInteraction();
            playAction(animationNames.thinking, THREE.LoopRepeat);
            
            try {
                const response = await fetchGeminiResponse(message);
                const botResponse = response.candidates[0].content.parts[0].text;
                appendMessage(botResponse, 'bot-message');
                speakText(botResponse, () => {
                    playAction(animationNames.idle2, THREE.LoopRepeat);
                });
            } catch (error) {
                console.error("Gemini API Error:", error);
                playAction(animationNames.shake, THREE.LoopOnce);
                setTimeout(() => playAction(animationNames.idle2, THREE.LoopRepeat), actions[animationNames.shake].getClip().duration * 1000);
                appendMessage("Sorry, I'm having trouble connecting right now. Please try again later.", 'bot-message');
            }
        }

        async function fetchGeminiResponse(prompt) {
            const chatHistory = [{ role: "user", parts: [{ text: prompt }] }];
            const payload = { contents: chatHistory };
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            return response.json();
        }

        function appendMessage(text, className) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('chat-message', 'rounded-xl', 'p-3', 'shadow-md', 'max-w-[70%]');
            messageDiv.classList.add(className);
            messageDiv.innerText = text;
            chatHistory.appendChild(messageDiv);
            chatHistory.scrollTop = chatHistory.scrollHeight; // Scroll to the bottom
        }

        // --- Text-to-Speech (TTS) Functions ---

        async function speakText(text, onEndCallback = () => {}) {
            if (ttsAudioSource) {
                ttsAudioSource.stop();
                ttsAudioSource = null;
            }

            playAction(animationNames.talk, THREE.LoopRepeat);
            isTalking = true;

            const payload = {
                contents: [{ parts: [{ text: text }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: "Kore" }
                        }
                    }
                },
                model: "gemini-2.5-flash-preview-tts"
            };

            const response = await fetch(ttsApiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            const result = await response.json();
            const part = result?.candidates?.[0]?.content?.parts?.[0];
            const audioData = part?.inlineData?.data;
            const mimeType = part?.inlineData?.mimeType;

            if (audioData && mimeType && mimeType.startsWith("audio/")) {
                const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
                const pcmData = base64ToArrayBuffer(audioData);
                const pcm16 = new Int16Array(pcmData);

                // Create a WAV container
                const wavBlob = pcmToWav(pcm16, sampleRate);
                const audioUrl = URL.createObjectURL(wavBlob);

                const audio = new Audio(audioUrl);
                audio.play();

                audio.onended = () => {
                    isTalking = false;
                    onEndCallback();
                };
            } else {
                console.error("TTS API returned no audio data.");
                isTalking = false;
                onEndCallback();
            }
        }

        function pcmToWav(pcm16, sampleRate) {
            const numSamples = pcm16.length;
            const buffer = new ArrayBuffer(44 + numSamples * 2);
            const view = new DataView(buffer);
            let offset = 0;

            function writeString(str) {
                for (let i = 0; i < str.length; i++) {
                    view.setUint8(offset++, str.charCodeAt(i));
                }
            }

            function writeUint32(val) {
                view.setUint32(offset, val, true);
                offset += 4;
            }

            function writeUint16(val) {
                view.setUint16(offset, val, true);
                offset += 2;
            }

            writeString('RIFF');
            writeUint32(36 + numSamples * 2);
            writeString('WAVE');
            writeString('fmt ');
            writeUint32(16);
            writeUint16(1); // Audio format (1 for PCM)
            writeUint16(1); // Num channels
            writeUint32(sampleRate);
            writeUint32(sampleRate * 2); // Byte rate
            writeUint16(2); // Block align
            writeUint16(16); // Bits per sample
            writeString('data');
            writeUint32(numSamples * 2);

            for (let i = 0; i < numSamples; i++) {
                view.setInt16(offset, pcm16[i], true);
                offset += 2;
            }

            return new Blob([view], { type: 'audio/wav' });
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }


        // --- Speech Recognition ---
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                speechRecognition = new webkitSpeechRecognition();
                speechRecognition.continuous = false;
                speechRecognition.interimResults = false;
                speechRecognition.lang = 'en-US';

                speechRecognition.onstart = () => {
                    console.log("Speech recognition started.");
                    isListening = true;
                    playAction(animationNames.listening, THREE.LoopRepeat);
                    micButton.classList.add('listening-button');
                    appendMessage("Go ahead, I'm listening...", 'bot-message');
                };

                speechRecognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    console.log("Speech recognized:", transcript);
                    chatInput.value = transcript;
                    onSendMessage();
                };

                speechRecognition.onend = () => {
                    console.log("Speech recognition ended.");
                    isListening = false;
                    playAction(animationNames.idle2, THREE.LoopRepeat);
                    micButton.classList.remove('listening-button');
                };

                speechRecognition.onerror = (event) => {
                    console.error("Speech recognition error:", event.error);
                    isListening = false;
                    playAction(animationNames.shake, THREE.LoopOnce);
                    setTimeout(() => playAction(animationNames.idle2, THREE.LoopRepeat), actions[animationNames.shake].getClip().duration * 1000);
                    micButton.classList.remove('listening-button');
                    appendMessage("Sorry, I didn't catch that. Can you please type it out?", 'bot-message');
                };

            } else {
                console.warn("Web Speech Recognition API is not supported in this browser.");
                micButton.style.display = 'none';
            }
        }

        function toggleSpeechRecognition() {
            reactToInteraction();
            if (isListening) {
                speechRecognition.stop();
            } else {
                speechRecognition.start();
            }
        }

        // --- Avatar Behavior (Idle/Patrol) ---

        function startIdleSequence() {
            stopPatrol();
            clearTimeout(idleTimeoutId);

            idleTimeoutId = setTimeout(() => {
                if (!isTalking && !isListening && !isMoving) {
                    playAction(animationNames.idle, THREE.LoopRepeat);
                    patrolTimeoutId = setTimeout(startPatrol, IDLE_TIMEOUT_30 - IDLE_TIMEOUT_10);
                }
            }, IDLE_TIMEOUT_10);
        }

        function startPatrol() {
            if (isTalking || isListening || isMoving) return;
            isPatrolling = true;
            patrolLoop();
        }

        function patrolLoop() {
            if (!isPatrolling) return;

            const targetX = (Math.random() - 0.5) * 5;
            const targetZ = (Math.random() - 0.5) * 5;
            moveAvatarTo(new THREE.Vector3(targetX, 0, targetZ));

            setTimeout(() => {
                if (isPatrolling) {
                    patrolLoop();
                }
            }, 10000); // Wait 10 seconds at each point
        }

        function stopPatrol() {
            isPatrolling = false;
            clearTimeout(idleTimeoutId);
            clearTimeout(patrolTimeoutId);
        }

        // --- Animation Utility Functions ---
        function playAction(name, loopMode) {
            if (!actions[name]) {
                console.error(`Animation action "${name}" not found.`);
                return;
            }

            if (currentAction) {
                currentAction.fadeOut(0.2);
            }
            
            const newAction = actions[name];
            newAction.reset().fadeIn(0.2).play();
            newAction.setLoop(loopMode);
            currentAction = newAction;
        }

        function findBones(object) {
            object.traverse((child) => {
                if (child.isBone) {
                    if (child.name === leftEyeBoneName) leftEye = child;
                    if (child.name === rightEyeBoneName) rightEye = child;
                    if (child.name === headBoneName) headBone = child;
                    if (child.name === jawBoneName) jawBone = child;
                }
            });
        }
        
        // --- Dance Music and Animation Logic ---
        function onDanceButtonClick() {
            reactToInteraction();
            if (Tone.context.state !== 'running') {
                Tone.context.resume();
            }
            playAction(animationNames.dance, THREE.LoopOnce);
            startDanceMusic();
        }

        function startDanceMusic() {
            stopDanceMusic(); // Ensure any previous music is stopped

            const synth = new Tone.MembraneSynth().toDestination();
            danceLoop = new Tone.Loop(time => {
                synth.triggerAttackRelease("C2", "8n", time);
            }, "4n").start(0);

            Tone.Transport.start();
        }

        function stopDanceMusic() {
            if (danceLoop) {
                danceLoop.stop();
                danceLoop.dispose();
                danceLoop = null;
            }
            Tone.Transport.stop();
        }
    </script>
</body>
</html>
