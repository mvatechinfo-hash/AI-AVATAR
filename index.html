<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI-AVATAR</title>

    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/tone@14.7.58/build/Tone.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            background: #111827;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        canvas {
            display: block;
            touch-action: none;
        }
        .chat-ui-container {
            position: absolute;
            bottom: 20px;
            right: 20px;
            top: 20px;
            padding: 1rem;
            width: 100%;
            max-width: 400px;
            z-index: 10;
            display: flex;
            flex-direction: column;
            background-color: #1f2937;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .message-box {
            background-color: #374151;
            color: #d1d5db;
            padding: 0.75rem 1rem;
            border-radius: 1rem;
            margin-bottom: 0.5rem;
            max-width: 80%;
            word-wrap: break-word;
        }
        .user-message {
            align-self: flex-end;
            background-color: #3b82f6;
            color: white;
        }
        .avatar-message {
            align-self: flex-start;
        }
        .pulse-effect {
            animation: pulse-animation 1.5s infinite;
        }
        @keyframes pulse-animation {
            0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(60, 179, 113, 0.7); }
            70% { transform: scale(1.1); box-shadow: 0 0 0 10px rgba(60, 179, 113, 0); }
            100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(60, 179, 113, 0); }
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200 h-screen w-screen relative">
    
    <!-- Loading Screen -->
    <div id="loading-screen" class="absolute inset-0 flex flex-col items-center justify-center bg-gray-900 z-50 transition-opacity duration-500">
        <h1 class="text-4xl font-bold text-white mb-4">Loading 3D Avatar...</h1>
        <div class="w-64 h-4 bg-gray-700 rounded-full overflow-hidden">
            <div id="loading-bar" class="h-full bg-blue-500 transition-all duration-300 ease-in-out" style="width: 0%;"></div>
        </div>
    </div>

    <!-- Main 3D canvas will be here -->
    <div id="scene-container" class="absolute inset-0 z-0"></div>

    <!-- Chat UI Container -->
    <div id="chat-ui-container" class="chat-ui-container hidden">
        <!-- Chat Messages Display -->
        <div id="chat-messages" class="flex-grow overflow-y-auto space-y-4 p-4 rounded-lg bg-gray-800 mb-4 custom-scrollbar">
            <!-- Messages will be appended here -->
        </div>

        <!-- Message Input Area -->
        <div class="flex items-center space-x-2">
            <input type="text" id="user-input" class="flex-grow p-3 rounded-full bg-gray-700 text-white placeholder-gray-400 focus:outline-none focus:ring-2 focus:ring-blue-500" placeholder="Type your message...">
            <button id="send-button" class="p-3 bg-blue-600 text-white rounded-full hover:bg-blue-700 transition-colors">
                <i class="fas fa-paper-plane"></i>
            </button>
            <button id="audio-button" class="p-3 bg-green-600 text-white rounded-full hover:bg-green-700 transition-colors">
                <i class="fas fa-microphone"></i>
            </button>
            <button id="dance-button" class="p-3 bg-purple-600 text-white rounded-full hover:bg-purple-700 transition-colors">
                <i class="fas fa-music"></i>
            </button>
        </div>
    </div>
    
    <!-- Toast Notification Container -->
    <div id="toast-container" class="absolute bottom-20 left-1/2 -translate-x-1/2 flex flex-col items-center space-y-2 z-50"></div>
    
    <!-- Custom Modal for Alerts -->
    <div id="alert-modal" class="hidden fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center z-50">
        <div class="bg-gray-800 p-6 rounded-lg shadow-xl max-w-sm w-full">
            <h3 class="text-xl font-bold mb-4 text-white">Alert</h3>
            <p id="alert-message" class="text-gray-300 mb-6"></p>
            <button id="alert-ok-button" class="w-full bg-blue-600 text-white p-3 rounded-lg hover:bg-blue-700 transition-colors">OK</button>
        </div>
    </div>


    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.144.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.144.0/examples/jsm/"
            }
        }
    </script>
    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

        // Custom alert function to replace window.alert
        function customAlert(message) {
            const modal = document.getElementById('alert-modal');
            const messageElement = document.getElementById('alert-message');
            const okButton = document.getElementById('alert-ok-button');
            messageElement.textContent = message;
            modal.classList.remove('hidden');
            okButton.onclick = () => {
                modal.classList.add('hidden');
            };
        }
        
        // Use the API key provided by the user
        const API_KEY = "AIzaSyCWaPLRukI_Rhb8vB29vVjEk5GEuopXnA4";
        const TEXT_GENERATION_MODEL = 'gemini-2.5-flash-preview-05-20';
        const TTS_MODEL = 'gemini-2.5-flash-preview-tts';
        const VOICE_NAME = 'Kore'; // Male voice as requested

        // Set up the scene, camera, and renderer
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        renderer.toneMappingExposure = 1.0;
        renderer.setClearColor(0x111827, 0);
        document.getElementById('scene-container').appendChild(renderer.domElement);

        // Lights
        const ambientLight = new THREE.AmbientLight(0xffffff, 1.5);
        scene.add(ambientLight);
        
        const directionalLight = new THREE.DirectionalLight(0xffffff, 2);
        directionalLight.position.set(5, 10, 7.5);
        scene.add(directionalLight);

        // Camera position
        camera.position.z = 2.5;
        camera.position.y = 1.5;
        camera.position.x = 0;

        // OrbitControls
        const controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.05;
        controls.screenSpacePanning = false;
        controls.minDistance = 1.5;
        controls.maxDistance = 5;
        controls.target.set(0, 1.2, 0);
        controls.update();

        // Global variables for avatar and animations
        let avatar;
        let mixer;
        const animationNames = {
            idle_active: 'Idle.001',
            idle_passive: 'Idle',
            walking: 'Walking',
            wave: 'Idle.001',
            talking: 'Idle.001', // Using an existing animation for talking placeholder
            thinking: 'Idle', // Using an existing animation for thinking placeholder
            listening: 'Idle.001', // Using an existing animation for listening placeholder
            shake: 'Idle', // Using an existing animation for shake placeholder
            dance: 'Idle.001', // Using an existing animation for dance placeholder
        };
        let activeAction;
        let animations = {};
        let isMoving = false;
        let isTalking = false;
        let isTurning = false;
        let targetQuaternion = new THREE.Quaternion();
        let turnStartTime;
        let turnDuration = 1000;
        let lastInteractionTime = Date.now();
        let idleStart = Date.now();
        const idleActiveTimeout = 10000; // 10 seconds
        const patrolTimeout = 20000; // 20 seconds after passive idle
        let isPatrolling = false;
        let patrolTarget = new THREE.Vector3();
        let jawBone;
        let speechAudio;
        let audioContext;
        let audioSource;
        let speechDuration = 0;
        let isDanceMode = false;
        let danceMusic;
        let raycaster = new THREE.Raycaster();
        let mouse = new THREE.Vector2();
        let mouseLookTarget = new THREE.Vector3();

        // State for API calls and UI
        let isFetchingResponse = false;
        let isRecording = false;
        let speechRecognizer;

        // UI Elements
        const loadingScreen = document.getElementById('loading-screen');
        const loadingBar = document.getElementById('loading-bar');
        const chatUIContainer = document.getElementById('chat-ui-container');
        const userInput = document.getElementById('user-input');
        const sendButton = document.getElementById('send-button');
        const audioButton = document.getElementById('audio-button');
        const danceButton = document.getElementById('dance-button');
        const chatMessages = document.getElementById('chat-messages');

        // Loading Manager to track progress
        const manager = new THREE.LoadingManager();
        manager.onProgress = function (item, loaded, total) {
            const progress = (loaded / total) * 100;
            loadingBar.style.width = `${progress}%`;
        };
        manager.onLoad = function () {
            loadingScreen.style.opacity = '0';
            setTimeout(() => {
                loadingScreen.remove();
                chatUIContainer.classList.remove('hidden');
                // Initial greeting logic
                greetAvatar();
            }, 500);
            
            // Start with an active idle animation
            playAction(animationNames.idle_active, THREE.LoopRepeat);
            
            // Set up a listener for idle animations
            setInterval(checkIdleAndPatrol, 1000);
        };
        
        // GLTF Loader to load the avatar model
        const loader = new GLTFLoader(manager);
        loader.load(
            'https://models.readyplayer.me/65910419e59d9f94562080a2.glb',
            function (gltf) {
                avatar = gltf.scene;
                avatar.scale.set(1.1, 1.1, 1.1);
                avatar.position.y = -1;
                scene.add(avatar);

                // Create a simple ground plane for raycasting
                const groundGeometry = new THREE.PlaneGeometry(100, 100);
                const groundMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00, transparent: true, opacity: 0 });
                const ground = new THREE.Mesh(groundGeometry, groundMaterial);
                ground.rotation.x = -Math.PI / 2;
                ground.position.y = -1;
                scene.add(ground);

                // Find the jaw bone for talking animation and other parts for mouse-look
                avatar.traverse(child => {
                    if (child.isMesh) {
                        child.castShadow = true;
                        child.receiveShadow = true;
                    }
                    if (child.isBone && child.name === 'Jaw') {
                        jawBone = child;
                    }
                });

                // Set up animations
                mixer = new THREE.AnimationMixer(avatar);
                gltf.animations.forEach(clip => {
                    const action = mixer.clipAction(clip);
                    animations[clip.name] = action;
                });
            },
            undefined,
            function (error) {
                console.error('An error occurred loading the model:', error);
                showToast('Failed to load avatar model.', 'error');
            }
        );

        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        // Function to play a specific animation
        function playAction(name, loopMode = THREE.LoopOnce, clampWhenFinished = false) {
            if (!animations[name]) {
                console.warn(`Animation "${name}" not found. Playing placeholder idle animation.`);
                name = animationNames.idle_active;
            }
            if (activeAction) {
                activeAction.fadeOut(0.5);
            }
            activeAction = animations[name];
            activeAction.reset().fadeIn(0.5).play();
            activeAction.loop = loopMode;
            activeAction.clampWhenFinished = clampWhenFinished;
        }

        // Mouse move for mouse-look
        window.addEventListener('mousemove', (event) => {
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // This is a simple look-at implementation. A more advanced one would involve moving the head/eyes bone.
            // For now, let's just make the avatar's body slightly reactive to the mouse.
            if (avatar) {
                mouseLookTarget.x = camera.position.x + mouse.x * 2;
                mouseLookTarget.y = avatar.position.y + 1.2; // roughly head height
                mouseLookTarget.z = camera.position.z + mouse.y * 2;
                avatar.lookAt(mouseLookTarget);
            }
        });

        // Function to check for idle state
        function checkIdleAndPatrol() {
            const now = Date.now();
            const elapsed = now - lastInteractionTime;

            if (!isTalking && !isMoving && !isDanceMode) {
                if (elapsed > idleActiveTimeout && activeAction.getClip().name === animationNames.idle_active) {
                    // Transition to passive idle
                    playAction(animationNames.idle_passive, THREE.LoopRepeat);
                    idleStart = now;
                    isPatrolling = false;
                } else if (elapsed > idleActiveTimeout + patrolTimeout && !isPatrolling) {
                    // Start patrol mode
                    startPatrol();
                }
            }
        }
        
        function startPatrol() {
            isPatrolling = true;
            patrolAvatar();
        }

        function patrolAvatar() {
            if (!isPatrolling) return;
            // Move to a random position
            const x = (Math.random() - 0.5) * 4;
            const z = (Math.random() - 0.5) * 4;
            patrolTarget.set(x, avatar.position.y, z);
            moveAvatarToPoint(patrolTarget);
            setTimeout(patrolAvatar, 10000); // Move again after 10 seconds
        }
        
        // This function is for animated movements (like patrol)
        function moveAvatarToPoint(targetPosition) {
            if (!avatar || isMoving) {
                 return;
            }
            
            const direction = new THREE.Vector3().subVectors(targetPosition, avatar.position);
            const angle = Math.atan2(direction.x, direction.z);
            targetQuaternion.setFromAxisAngle(new THREE.Vector3(0, 1, 0), angle);
            
            isMoving = true;
            isTurning = true;
            turnStartTime = Date.now();

            playAction(animationNames.walking, THREE.LoopRepeat);
            resetIdleTimer();
        }

        // New function to instantly move the avatar to the front and make it face the camera
        function teleportToFront() {
            if (!avatar) return;
            // Define the front-facing position relative to the camera
            const frontPosition = new THREE.Vector3(0, avatar.position.y, 1.5);
            avatar.position.copy(frontPosition);

            // Set the rotation to face the camera instantly
            const direction = new THREE.Vector3().subVectors(camera.position, frontPosition);
            const angle = Math.atan2(direction.x, direction.z);
            avatar.quaternion.setFromAxisAngle(new THREE.Vector3(0, 1, 0), angle);

            // Stop any ongoing movements
            isMoving = false;
            isTurning = false;
            
            resetIdleTimer();
        }
        
        // Function to reset the idle timer
        function resetIdleTimer() {
            lastInteractionTime = Date.now();
            isPatrolling = false;
            if (activeAction && activeAction.getClip().name !== animationNames.idle_active) {
                playAction(animationNames.idle_active, THREE.LoopRepeat);
            }
        }
        
        // Function to append messages to the chat UI
        function appendMessage(sender, message) {
            const messageElement = document.createElement('div');
            messageElement.classList.add('message-box');
            if (sender === 'user') {
                messageElement.classList.add('user-message');
            } else {
                messageElement.classList.add('avatar-message');
            }
            messageElement.innerText = message;
            chatMessages.appendChild(messageElement);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        // Function to display toast notifications
        function showToast(message, type = 'info') {
            const toast = document.createElement('div');
            toast.className = `p-4 rounded-lg shadow-lg text-white font-bold transition-transform transform duration-300 translate-y-10 opacity-0`;

            if (type === 'error') {
                toast.classList.add('bg-red-500');
            } else if (type === 'success') {
                toast.classList.add('bg-green-500');
            } else {
                toast.classList.add('bg-gray-500');
            }

            toast.textContent = message;

            const toastContainer = document.getElementById('toast-container');
            toastContainer.appendChild(toast);

            setTimeout(() => {
                toast.style.transform = 'translateY(0)';
                toast.style.opacity = '1';
            }, 100);

            setTimeout(() => {
                toast.style.transform = 'translateY(10px)';
                toast.style.opacity = '0';
                toast.addEventListener('transitionend', () => toast.remove());
            }, 3000);
        }

        // --- Core Chatbot Functionality ---
        async function getAvatarResponse(text) {
            if (isFetchingResponse) return;
            isFetchingResponse = true;
            playAction(animationNames.thinking, THREE.LoopRepeat);
            
            try {
                const chatHistory = [];
                chatHistory.push({ role: "user", parts: [{ text: text }] });
                const payload = { contents: chatHistory };
                
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${TEXT_GENERATION_MODEL}:generateContent?key=${API_KEY}`;
                
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                
                const result = await response.json();
                
                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const avatarResponseText = result.candidates[0].content.parts[0].text;
                    appendMessage('avatar', avatarResponseText);
                    await getTTS(avatarResponseText);
                } else {
                    console.error("Unexpected API response structure:", result);
                    playAction(animationNames.shake, THREE.LoopOnce);
                    showToast('Sorry, I couldn\'t generate a response.', 'error');
                }
            } catch (error) {
                console.error("Error fetching Gemini API:", error);
                playAction(animationNames.shake, THREE.LoopOnce);
                showToast('API call failed. Please try again.', 'error');
            } finally {
                isFetchingResponse = false;
                playAction(animationNames.idle_active, THREE.LoopRepeat);
            }
        }

        async function getTTS(text) {
            isTalking = true;
            playAction(animationNames.talking, THREE.LoopRepeat);
            
            try {
                const payload = {
                    contents: [{
                        parts: [{ text: text }]
                    }],
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: {
                            voiceConfig: {
                                prebuiltVoiceConfig: { voiceName: VOICE_NAME }
                            }
                        }
                    },
                    model: TTS_MODEL
                };
                
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${TTS_MODEL}:generateContent?key=${API_KEY}`;
                
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                
                const result = await response.json();
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (audioData && mimeType && mimeType.startsWith("audio/")) {
                    const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
                    const pcmData = base64ToArrayBuffer(audioData);
                    const pcm16 = new Int16Array(pcmData);
                    const wavBlob = pcmToWav(pcm16, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    const audio = new Audio(audioUrl);
                    speechDuration = audio.duration * 1000;
                    audio.play();

                    // Listen for when audio finishes
                    audio.onended = () => {
                        isTalking = false;
                        playAction(animationNames.idle_active, THREE.LoopRepeat);
                        resetIdleTimer();
                    };
                } else {
                    console.error("TTS response error:", result);
                    showToast('TTS failed. Could not generate audio.', 'error');
                    isTalking = false;
                    playAction(animationNames.idle_active, THREE.LoopRepeat);
                }
            } catch (error) {
                console.error("Error fetching TTS API:", error);
                showToast('TTS API call failed.', 'error');
                isTalking = false;
                playAction(animationNames.idle_active, THREE.LoopRepeat);
            }
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function pcmToWav(pcm16, sampleRate) {
            const dataLength = pcm16.length * 2;
            const buffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(buffer);
            let offset = 0;

            function writeString(str) {
                for (let i = 0; i < str.length; i++) {
                    view.setUint8(offset++, str.charCodeAt(i));
                }
            }

            function writeUint32(value) {
                view.setUint32(offset, value, true);
                offset += 4;
            }

            function writeUint16(value) {
                view.setUint16(offset, value, true);
                offset += 2;
            }

            // RIFF chunk
            writeString('RIFF');
            writeUint32(36 + dataLength);
            writeString('WAVE');

            // fmt chunk
            writeString('fmt ');
            writeUint32(16);
            writeUint16(1); // PCM
            writeUint16(1); // Mono
            writeUint32(sampleRate);
            writeUint32(sampleRate * 2); // Byte rate
            writeUint16(2); // Block align
            writeUint16(16); // Bits per sample

            // data chunk
            writeString('data');
            writeUint32(dataLength);
            
            for (let i = 0; i < pcm16.length; i++) {
                view.setInt16(offset, pcm16[i], true);
                offset += 2;
            }

            return new Blob([view], { type: 'audio/wav' });
        }


        // --- Speech Recognition ---
        function startRecording() {
            if (isRecording) return;
            isRecording = true;
            
            // Webkit Speech Recognition API
            if ('webkitSpeechRecognition' in window) {
                speechRecognizer = new webkitSpeechRecognition();
                speechRecognizer.continuous = false;
                speechRecognizer.interimResults = false;
                speechRecognizer.lang = 'en-US';

                speechRecognizer.onstart = () => {
                    audioButton.classList.add('pulse-effect');
                    audioButton.querySelector('i').className = 'fas fa-microphone-slash';
                    playAction(animationNames.listening, THREE.LoopRepeat);
                    appendMessage('avatar', "Go ahead, I'm listening.");
                    showToast("Listening...", "info");
                    isTalking = true;
                    teleportToFront();
                };

                speechRecognizer.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    appendMessage('user', transcript);
                    getAvatarResponse(transcript);
                    isTalking = false;
                };

                speechRecognizer.onerror = (event) => {
                    console.error("Speech recognition error:", event.error);
                    showToast('Speech recognition error. Please try again.', 'error');
                    stopRecording();
                };

                speechRecognizer.onend = () => {
                    stopRecording();
                };

                speechRecognizer.start();

            } else {
                showToast('Speech recognition not supported in this browser.', 'error');
                isRecording = false;
            }
        }

        function stopRecording() {
            if (!isRecording) return;
            isRecording = false;
            if (speechRecognizer) {
                speechRecognizer.stop();
            }
            audioButton.classList.remove('pulse-effect');
            audioButton.querySelector('i').className = 'fas fa-microphone';
            playAction(animationNames.idle_active, THREE.LoopRepeat);
        }

        // --- Dance Mode ---
        function startDanceMode() {
            if (isDanceMode) return;
            isDanceMode = true;
            
            // Make the avatar face forward
            teleportToFront();

            // Play dance animation
            playAction(animationNames.dance, THREE.LoopOnce);

            // Create and play a simple drum beat with Tone.js
            danceMusic = new Tone.MembraneSynth().toDestination();
            const loop = new Tone.Loop(time => {
                danceMusic.triggerAttackRelease("C1", "8n", time);
            }, "4n").start(0);

            Tone.Transport.start();

            // Stop the music and dance when animation finishes
            activeAction.clampWhenFinished = true;
            mixer.addEventListener('finished', () => {
                stopDanceMode();
            });

            resetIdleTimer();
        }

        function stopDanceMode() {
            if (!isDanceMode) return;
            isDanceMode = false;
            if (danceMusic) {
                Tone.Transport.stop();
                danceMusic.dispose();
                danceMusic = null;
            }
            playAction(animationNames.idle_active, THREE.LoopRepeat);
            mixer.removeEventListener('finished', stopDanceMode);
        }

        // --- Initial Greeting ---
        async function greetAvatar() {
            teleportToFront(); // Teleport to front and face the user on greeting
            playAction(animationNames.wave, THREE.LoopOnce);
            isTalking = true;
            await getTTS("Hello there!");
            await new Promise(resolve => setTimeout(resolve, 1500)); // Wait for a moment
            await getTTS("What can I do for you?");
        }
        
        // --- Event Listeners ---
        // Handle sending messages
        sendButton.addEventListener('click', () => {
            const message = userInput.value.trim();
            if (message) {
                appendMessage('user', message);
                userInput.value = '';
                getAvatarResponse(message);
                teleportToFront(); // Instant teleport
            }
        });

        userInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendButton.click();
            }
        });

        // Toggle recording on audio button click
        audioButton.addEventListener('click', () => {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
            teleportToFront(); // Instant teleport
        });

        // Toggle dance mode
        danceButton.addEventListener('click', () => {
            if (isDanceMode) {
                stopDanceMode();
            } else {
                startDanceMode();
            }
        });

        // Handle clicks on the canvas for movement and avatar interaction
        renderer.domElement.addEventListener('click', (event) => {
            // First, teleport to the front.
            teleportToFront();

            // Then, check if the click was on the avatar.
            raycaster.setFromCamera(mouse, camera);
            const intersects = raycaster.intersectObject(avatar, true);
            if (intersects.length > 0) {
                console.log('Avatar clicked!');
                greetAvatar();
                return;
            }

            // Otherwise, move the avatar to the clicked point on the ground (this will be an animated movement)
            const groundIntersects = raycaster.intersectObject(scene.children.find(o => o.geometry.type === 'PlaneGeometry'));
            if (groundIntersects.length > 0) {
                moveAvatarToPoint(groundIntersects[0].point);
            }
        });
        
        // Handle clicks on the chat UI container
        chatUIContainer.addEventListener('click', () => {
            teleportToFront(); // Instant teleport
        });

        // Start the animation loop
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);

            const delta = clock.getDelta();
            const time = clock.getElapsedTime();

            // Lip-syncing animation
            if (isTalking && jawBone) {
                // Animate the jaw bone based on a sine wave for a simple lip-sync effect
                const jawRotation = Math.sin(time * 10) * 0.05 + 0.02;
                jawBone.rotation.x = -jawRotation;
            } else if (jawBone) {
                jawBone.rotation.x = 0;
            }
            
            // Movement and turning logic
            if (isMoving || isTurning) {
                // Slerp for turning animation
                if (isTurning) {
                    const elapsedTime = Date.now() - turnStartTime;
                    const turnProgress = Math.min(elapsedTime / turnDuration, 1);
                    avatar.quaternion.slerp(targetQuaternion, turnProgress);
                    if (turnProgress >= 1) {
                        isTurning = false;
                    }
                }

                // If not turning, or if turning is finished, handle movement
                if (!isTurning && isMoving) {
                    const distance = avatar.position.distanceTo(patrolTarget);
                    if (distance > 0.05) {
                        const direction = new THREE.Vector3().subVectors(patrolTarget, avatar.position).normalize();
                        avatar.position.addScaledVector(direction, 0.008);
                    } else {
                        avatar.position.copy(patrolTarget);
                        isMoving = false;
                        playAction(animationNames.idle_active, THREE.LoopRepeat);
                        lastInteractionTime = Date.now();
                    }
                }
            }
            
            if (mixer) mixer.update(delta);
            controls.update(); // only required if controls.enableDamping is set to true
            renderer.render(scene, camera);
        }

        // Mouse move event listener for raycaster
        window.addEventListener('mousemove', (event) => {
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;
        }, false);
        
        window.onload = function () {
            animate();
        }
    </script>
</body>
</html>
